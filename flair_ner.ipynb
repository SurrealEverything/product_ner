{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d570954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install flair beautifulsoup4 pdfkit\n",
    "# !sudo apt-get install wkhtmltopdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f722020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-24 19:07:41,254 --------------------------------------------------------------------------------\n",
      "2022-01-24 19:07:41,255 The model key 'ner-ontonotes-large' now maps to 'https://huggingface.co/flair/ner-english-ontonotes-large' on the HuggingFace ModelHub\n",
      "2022-01-24 19:07:41,255  - The most current version of the model is automatically downloaded from there.\n",
      "2022-01-24 19:07:41,255 --------------------------------------------------------------------------------\n",
      "2022-01-24 19:07:41,834 loading file /home/gabriel/.flair/models/ner-english-ontonotes-large/2da6c2cdd76e59113033adf670340bfd820f0301ae2e39204d67ba2dc276cc28.ec1bdb304b6c66111532c3b1fc6e522460ae73f1901848a4d0362cdf9760edb1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from flair.data import Sentence \n",
    "from flair.models import SequenceTagger\n",
    "from tqdm.auto import tqdm\n",
    "from segtok.segmenter import split_single\n",
    "import logging\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "tagger = SequenceTagger.load('ner-ontonotes-large')  # ner-ontonotes-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0c827d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(urls, char_limit=100000, page_limit=None):\n",
    "\n",
    "    urls = pd.read_csv('furniture stores pages.csv').values.squeeze().tolist()[:page_limit]\n",
    "    pages = []\n",
    "    \n",
    "    for url in urls:\n",
    "\n",
    "        try:\n",
    "\n",
    "            data = requests.get(url)\n",
    "            soup = BeautifulSoup(data.content, 'html.parser')\n",
    "            tags = soup.find_all()\n",
    "\n",
    "            text = []\n",
    "            blacklist = [\n",
    "                '[document]',\n",
    "                'noscript',\n",
    "                'header',\n",
    "                'html',\n",
    "                'meta',\n",
    "                'head',\n",
    "                'input',\n",
    "                'script',\n",
    "                'style',\n",
    "                'title'\n",
    "            ]\n",
    "\n",
    "            for t in tags:\n",
    "                if t.name not in blacklist and t.parent.name not in blacklist:\n",
    "                    clean_text = \" \".join(t.text.split())\n",
    "                    if len(clean_text) > 1:\n",
    "                        text.append(clean_text)\n",
    "\n",
    "#             if len(clean_text) > char_limit:\n",
    "#                 print(clean_text)\n",
    "#                 print(len(clean_text))\n",
    "#                 clean_text = clean_text[:char_limit]\n",
    "    \n",
    "            pages.append(text)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.exception(str(e))\n",
    "            pages.append(np.nan)\n",
    "\n",
    "    df = pd.DataFrame(columns=['raw_text'])\n",
    "    df['raw_text'] = pages\n",
    "    # df = df.replace(np.nan, '', regex=True)\n",
    "    return df\n",
    "\n",
    "df = build_dataset('furniture stores pages.csv', page_limit=5)\n",
    "df.to_csv('pages_content.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b91a1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a9506ec6a142f6b03dd42216d2de5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pages Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sentences Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sentences Progress:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span [3,4,5,6]: \"Cirrus LED Reading Light\"   [− Labels: PRODUCT (0.9991)]\n",
      "Span [13]: \"Cirrus\"   [− Labels: PRODUCT (0.9999)]\n",
      "Span [12]: \"Beadlight\"   [− Labels: PRODUCT (0.9097)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sentences Progress:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sentences Progress:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span [14,15,16]: \"Waterfall Seat Edge\"   [− Labels: PRODUCT (0.9779)]\n",
      "Span [14,15,16]: \"Waterfall Seat Edge\"   [− Labels: PRODUCT (0.9779)]\n",
      "Span [14,15,16]: \"Waterfall Seat Edge\"   [− Labels: PRODUCT (0.9779)]\n",
      "Span [16]: \"Edge\"   [− Labels: PRODUCT (0.9225)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sentences Progress:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def batch(iterable, n=16):\n",
    "    l = len(iterable)\n",
    "    for ndx in tqdm(range(0, l // 3, n), leave=False, desc='Sentences Progress'):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "pages = pd.read_csv('pages_content.csv')['raw_text'].values.tolist()\n",
    "\n",
    "for page in tqdm(pages, desc='Pages Progress'):\n",
    "    page = ast.literal_eval(page)\n",
    "    sentences = [Sentence(sent, use_tokenizer=True) for line in page for sent in split_single(line)\n",
    "                 if sent != '' and sent != ' ' and sent != '\\n' and sent != '\\t' and len(sent) <= 512]\n",
    "    \n",
    "    for sent_batch in batch(sentences):        \n",
    "        tagger.predict(sent_batch)\n",
    "\n",
    "    for sent in sentences:\n",
    "        for entity in sent.get_spans('ner'):\n",
    "            if entity.tag == 'PRODUCT' and entity.score > 0.9:\n",
    "                print(entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6979be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
